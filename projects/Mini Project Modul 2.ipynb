{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04e18a0",
   "metadata": {},
   "source": [
    "# Proyek Mini Modul 2: Analisis Data Penjualan Ritel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7e734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b11e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langkah 1: Memuat Data\n",
    "# Data didapat dari https://www.kaggle.com/datasets/rohitsahoo/sales-forecasting\n",
    "try:\n",
    "    df = pd.read_csv('C:/Users/ASUS/Documents/Road to DA/Dataset Mini Project Modul 2.csv', encoding='latin1')\n",
    "except FileNotFoundError:\n",
    "    print(\"File tidak ditemukan. Pastikan 'Dataset Mini Project Modul 2.csv' ada di folder yang sama.\")\n",
    "    df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"Gagal memuat data. Error: {e}\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8383d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5 Baris Data Pertama ---\n",
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
      "1       2  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
      "2       3  CA-2017-138688  12/06/2017  16/06/2017    Second Class    DV-13045   \n",
      "3       4  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
      "4       5  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City       State  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
      "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
      "\n",
      "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
      "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3      33311.0  South  FUR-TA-10000577        Furniture       Tables   \n",
      "4      33311.0  South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  \n",
      "0                  Bush Somerset Collection Bookcase  261.9600  \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400  \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200  \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775  \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680  \n",
      "\n",
      "\n",
      "--- Statistik Deskriptif (untuk kolom numerik) ---\n",
      "            Row ID   Postal Code         Sales\n",
      "count  9800.000000   9789.000000   9800.000000\n",
      "mean   4900.500000  55273.322403    230.769059\n",
      "std    2829.160653  32041.223413    626.651875\n",
      "min       1.000000   1040.000000      0.444000\n",
      "25%    2450.750000  23223.000000     17.248000\n",
      "50%    4900.500000  58103.000000     54.490000\n",
      "75%    7350.250000  90008.000000    210.605000\n",
      "max    9800.000000  99301.000000  22638.480000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Langkah 2: Inspeksi Awal Data\n",
    "print(\"--- 5 Baris Data Pertama ---\")\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--- Statistik Deskriptif (untuk kolom numerik) ---\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a64adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Jumlah Missing Values per Kolom ---\n",
      "Row ID            0\n",
      "Order ID          0\n",
      "Order Date        0\n",
      "Ship Date         0\n",
      "Ship Mode         0\n",
      "Customer ID       0\n",
      "Customer Name     0\n",
      "Segment           0\n",
      "Country           0\n",
      "City              0\n",
      "State             0\n",
      "Postal Code      11\n",
      "Region            0\n",
      "Product ID        0\n",
      "Category          0\n",
      "Sub-Category      0\n",
      "Product Name      0\n",
      "Sales             0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Row ID           0\n",
      "Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Langkah 3: Pembersihan Data (Data Cleaning)\n",
    "# Menangani Missing Values\n",
    "print(\"--- Jumlah Missing Values per Kolom ---\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Menghapus Missing Values\n",
    "df = df.dropna()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb57d764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Jumlah Baris Duplikat: 0 ---\n"
     ]
    }
   ],
   "source": [
    "# Menangani Data Duplikat\n",
    "print(f\"\\n--- Jumlah Baris Duplikat: {df.duplicated().sum()} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc303cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9789 entries, 0 to 9799\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Row ID         9789 non-null   int64         \n",
      " 1   Order ID       9789 non-null   object        \n",
      " 2   Order Date     9789 non-null   datetime64[ns]\n",
      " 3   Ship Date      9789 non-null   object        \n",
      " 4   Ship Mode      9789 non-null   object        \n",
      " 5   Customer ID    9789 non-null   object        \n",
      " 6   Customer Name  9789 non-null   object        \n",
      " 7   Segment        9789 non-null   object        \n",
      " 8   Country        9789 non-null   object        \n",
      " 9   City           9789 non-null   object        \n",
      " 10  State          9789 non-null   object        \n",
      " 11  Postal Code    9789 non-null   float64       \n",
      " 12  Region         9789 non-null   object        \n",
      " 13  Product ID     9789 non-null   object        \n",
      " 14  Category       9789 non-null   object        \n",
      " 15  Sub-Category   9789 non-null   object        \n",
      " 16  Product Name   9789 non-null   object        \n",
      " 17  Sales          9789 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(14)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mengubah Tipe Data\n",
    "# 'Order Date' dari object menjadi datetime\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c0235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Total Penjualan per Kategori Produk ---\n",
      "Category\n",
      "Technology         825856.1130\n",
      "Furniture          723538.4757\n",
      "Office Supplies    703212.8240\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Langkah 4: Analisis\n",
    "\n",
    "# 1. Kategori produk ('Category') mana yang memiliki total penjualan ('Sales') tertinggi\n",
    "sales_per_category = df.groupby('Category')['Sales'].sum().sort_values(ascending=False)\n",
    "print(\"\\n--- Total Penjualan per Kategori Produk ---\")\n",
    "print(sales_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8b95bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Total Keuntungan per Region ---\n",
      "Region\n",
      "West       710219.6845\n",
      "East       660589.3560\n",
      "Central    492646.9132\n",
      "South      389151.4590\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. Region mana yang memiliki total penjualan ('Sales') tertinggi\n",
    "sales_per_region = df.groupby('Region')['Sales'].sum().sort_values(ascending=False)\n",
    "print(\"\\n--- Total Keuntungan per Region ---\")\n",
    "print(sales_per_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e1ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tren Penjualan Tahunan ---\n",
      "Year\n",
      "2015    479856.2081\n",
      "2016    454315.9054\n",
      "2017    597225.4900\n",
      "2018    721209.8092\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "\n",
      "--- Analisis Selesai ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Bagaimana tren penjualan ('Sales') dari tahun ke tahun\n",
    "if 'Order Date' in df.columns and pd.api.types.is_datetime64_any_dtype(df['Order Date']):\n",
    "    df['Year'] = df['Order Date'].dt.year\n",
    "    sales_per_year = df.groupby('Year')['Sales'].sum()\n",
    "    print(\"\\n--- Tren Penjualan Tahunan ---\")\n",
    "    print(sales_per_year)\n",
    "else:\n",
    "    print(\"\\nKolom 'Order Date' belum diubah menjadi datetime. Lewati analisis tren tahunan.\")\n",
    "\n",
    "print(\"\\n\\n--- Analisis Selesai ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d051a",
   "metadata": {},
   "source": [
    "Tambahan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hasil analisis berhasil disimpan ke file CSV! ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Menyimpan DataFrame yang sudah bersih\n",
    "df.to_csv('(Cleaned)Dataset Mini Project Modul 2.csv', index=False)\n",
    "\n",
    "# 2. Menyimpan hasil agregasi yang akan kita gunakan untuk visualisasi\n",
    "sales_per_category.to_csv('hasil_sales_per_category.csv')\n",
    "sales_per_region.to_csv('hasil_sales_per_region.csv')\n",
    "sales_per_year.to_csv('hasil_sales_per_year.csv')\n",
    "\n",
    "print(\"\\n--- Hasil analisis berhasil disimpan ke file CSV! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564ebe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
